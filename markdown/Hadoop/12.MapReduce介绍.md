# 定义

MapReduce 是一个**分布式运算程序的编程框架**，是用户开发“基于 Hadoop 的数据分析应用”的核心框架。 

MapReduce 核心功能是将 用户编写的业务逻辑代码 和  自带默认组件  整合成一个完整的分布式运算程序，并发运行在一个 Hadoop 集群上。



# 优缺点

## 优点

**1）MapReduce 易于编程**

它简单的实现一些接口，就可以完成一个分布式程序，这个分布式程序可以分布到大量廉价的 PC 机器上运行。

也就是说你写一个分布式程序，跟写一个简单的串行程序是一模一 样的。就是因为这个特点使得 MapReduce 编程变得非常流行。 



**2）良好的扩展性**

当你的计算资源不能得到满足的时候，你可以通过简单的增加机器来扩展它的计算能力。



 **3）高容错性**

MapReduce 设计的初衷就是使程序能够部署在廉价的 PC 机器上，这就要求它具有很高的容错性。

比如其中一台机器挂了，它可以把上面的计算任务转移到另外一个节点上运行， 不至于这个任务运行失败，而且这个过程不需要人工参与，而完全是由 Hadoop 内部完成的。



 **4）适合 PB 级以上海量数据的离线处理**

可以实现上千台服务器集群并发工作，提供数据处理能力。



## 缺点 

**1）不擅长实时计算**

MapReduce 无法像 MySQL 一样，在毫秒或者秒级内返回结果。



 **2）不擅长流式计算**（SparkStreaming flink）

流式计算的输入数据是动态的，而 MapReduce 的输入数据集是静态的，不能动态变化。 这是因为 MapReduce 自身的设计特点决定了数据源必须是静态的。 



**3）不擅长 DAG（有向无环图）计算**（Spark擅长）

多个应用程序存在依赖关系，后一个应用程序的输入为前一个的输出。在这种情况下， MapReduce 并不是不能做，而是使用后，每个 MapReduce 作业的输出结果都会写入到磁盘， 会造成大量的磁盘 IO，导致性能非常的低下。



# 编程核心思想

以WordCount程序为例：

![image-20220713141029530](.\picture\image-20220713141029530.png)

1.假设WordCount有两个input，分别为200m和100m，hdfs会将其分割为128m+72m+100m三个文件块

2.Map阶段，3个文件块就会在3个服务器中并行执行MapTask，读取文件块的文件，并将Key和Value值对应：(word, 1)

3.3个MapTask会各有两个结果放在两个分区，分别分区1为a-p开头，以及分区2q-z开头

4.Reduce阶段，第一个ReduceTask将所有分区1的加起来，输出为数据；第二个ReduceTask将所有分区1的加起来，输出为数据



# MR 进程

一个完整的 MapReduce 程序在分布式运行时有三类实例进程： 

## MrAppMaster

负责整个程序的过程调度及状态协调。



## **MapTask**（YarnChild）

负责 Map 阶段的整个数据处理流程。 



## ReduceTask（YarnChild）

负责 Reduce 阶段的整个数据处理流程。



# 官方WordCount源码

如何找到该源码？

%HADOOP_HOME%/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.3.jar

去反编译，找到WordCount类

## 重写Mapper类

```java
  public static class TokenizerMapper extends Mapper<Object, Text, Text, IntWritable>
  {
    private static final IntWritable one = new IntWritable(1);
    private Text word = new Text();

    public void map(Object key, Text value, Mapper<Object, Text, Text, IntWritable>.Context context) throws IOException, InterruptedException
    {
      StringTokenizer itr = new StringTokenizer(value.toString());
      while (itr.hasMoreTokens()) {
        this.word.set(itr.nextToken());
        context.write(this.word, one);
      }
    }
  }
```

**<Object, Text, Text, IntWritable>**

表示<输入的Key类型，输入的Value类型，输出的Key类型，输出的Value类型>

MapReduce有一套自己的类型



**public void map()**

重写此方法，编写业务逻辑



## 重写Reducer类

```Java
 public static class IntSumReducer extends Reducer<Text, IntWritable, Text, IntWritable>
  {
    private IntWritable result = new IntWritable();

    public void reduce(Text key, Iterable<IntWritable> values, Reducer<Text, IntWritable, Text, IntWritable>.Context context)
      throws IOException, InterruptedException
    {
      int sum = 0;
      for (IntWritable val : values) {
        sum += val.get();
      }
      this.result.set(sum);
      context.write(key, this.result);
    }
  }
```



## 驱动代码

```Java
public static void main(String[] args)
    throws Exception
  {
    Configuration conf = new Configuration();
    String[] otherArgs = new GenericOptionsParser(conf, args).getRemainingArgs();
    if (otherArgs.length < 2) {
      System.err.println("Usage: wordcount <in> [<in>...] <out>");
      System.exit(2);
    }
    Job job = Job.getInstance(conf, "word count");
    job.setJarByClass(WordCount.class);
    job.setMapperClass(TokenizerMapper.class);
    job.setCombinerClass(IntSumReducer.class);
    job.setReducerClass(IntSumReducer.class);
    job.setOutputKeyClass(Text.class);
    job.setOutputValueClass(IntWritable.class);
    for (int i = 0; i < otherArgs.length - 1; i++) {
      FileInputFormat.addInputPath(job, new Path(otherArgs[i]));
    }
    FileOutputFormat.setOutputPath(job, new Path(otherArgs[(otherArgs.length - 1)]));

    System.exit(job.waitForCompletion(true) ? 0 : 1);
  }

```



# 常用数据序列化类型

| Java类型   | Hadoop Writable类型 |
| ---------- | ------------------- |
| Boolean    | BooleanWritable     |
| Byte       | ByteWritable        |
| Int        | IntWritable         |
| Float      | FloatWritable       |
| Long       | LongWritable        |
| Double     | DoubleWritable      |
| **String** | **Text**            |
| Map        | MapWritable         |
| Array      | ArrayWritable       |
| Null       | NullWritable        |



# MD编程规范

## Mapper阶段 

（1）用户自定义的Mapper要继承自己的父类 

（2）Mapper的输入数据是KV对的形式（KV的类型可自定义） 

（3）Mapper中的业务逻辑写在map()方法中 

（4）Mapper的输出数据是KV对的形式（KV的类型可自定义） 

（5）map()方法（MapTask进程）对每一个调用一次



## Reducer阶段 

（1）用户自定义的Reducer要继承自己的父类

（2）Reducer的输入数据类型对应Mapper的输出数据类型，也是KV 

（3）Reducer的业务逻辑写在reduce()方法中 

（4）ReduceTask进程对每一组相同k的组调用一次reduce()方法



## Driver阶段 

相当于YARN集群的客户端，用于提交我们整个程序到YARN集群，提交的是 封装了MapReduce程序相关运行参数的job对象

