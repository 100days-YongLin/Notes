# MR框架原理

![image-20220716134136058](.\picture\image-20220716134136058.png)

# InputFormat 数据输入

## 切片与 MapTask 并行度决定机制

**MapTask并行度**：需要几个MapTask执行这个项目

MapTask 的并行度决定 Map 阶段的任务处理并发度，进而影响到整个 Job 的处理速度。



**MapTask 并行度决定机制**

数据块：Block 是 HDFS 物理上把数据分成一块一块。数据块是 HDFS 存储数据单位。 

数据切片：数据切片只是在逻辑上对输入进行分片，并不会在磁盘上将其切分成片进行 存储。

数据切片是 MapReduce 程序计算输入数据的单位，一个切片会对应启动一个 MapTask。



![image-20220716134428784](.\picture\image-20220716134428784.png)

如果切片大小为100M

因为数据块大小是128

则会导致 DN1里的数据 0-100分配一个MapTask1 100-128分配给MT2，因为不足100，又要去DN2里切割72M分配给MapTask2 等等这样 会非常浪费资源



如果切片大小是128M与数据块大小一样，则一个数据块分配一个MapTask，非常直观清晰好操作效率高



#  Job 提交流程源码

```Java
waitForCompletion()
submit();

// 1 建立连接
connect();
// 1）创建提交 Job 的代理
new Cluster(getConfiguration());
// （1）判断是本地运行环境还是 yarn 集群运行环境
initialize(jobTrackAddr, conf); 

// 2 提交 job
submitter.submitJobInternal(Job.this, cluster)
// 1）创建给集群提交数据的 Stag 路径
Path jobStagingArea = JobSubmissionFiles.getStagingDir(cluster, conf);

// 2）获取 jobid ，并创建 Job 路径
JobID jobId = submitClient.getNewJobID();

// 3）拷贝 jar 包到集群
copyAndConfigureFiles(job, submitJobDir);
rUploader.uploadFiles(job, jobSubmitDir);

// 4）计算切片，生成切片规划文件
writeSplits(job, submitJobDir);
maps = writeNewSplits(job, jobSubmitDir);
input.getSplits(job);

// 5）向 Stag 路径写 XML 配置文件
writeConf(conf, submitJobFile);
conf.writeXml(out);

// 6）提交 Job,返回提交状态
status = submitClient.submitJob(jobId, submitJobDir.toString(), 
job.getCredentials());
```



![image-20220716232555815](.\picture\image-20220716232555815.png)

stag目录下 根据jobid产生目录，并且会产生三个临时文件：



split:切片文件

xml:Job的所有配置文件

jar:Job的jar包



跑完之后这几个文件会删除



# FileInputFormat 切片

（input.getSplits(job)



## 源码解析

![image-20220716232949114](.\picture\image-20220716232949114.png)

InputSplit只是说了开始到结束是多少，在逻辑上的切片，物理上没有真正的切片



## 切片机制

![image-20220716233146105](.\picture\image-20220716233146105.png)

## 切片配置

![image-20220716233315754](.\picture\image-20220716233315754.png)



# 

# FileInputFormat 实现类

在运行 MapReduce 程序时，输入的文件格式包括：基于行的日志文件、二进制 格式文件、数据库表等。

那么，针对不同的数据类型，MapReduce 是如何读取这些数据的呢？

 FileInputFormat 常见的接口实现类包括：TextInputFormat、KeyValueTextInputFormat、 NLineInputFormat、CombineTextInputFormat 和自定义 InputFormat 等。

## TextInputFormat

TextInputFormat 是默认的 FileInputFormat 实现类。按行读取每条记录。

Key是存储该行在整个文件中的起始字节偏移量， LongWritable 类型。Value是这行的内容，不包括任何行终止 符（换行符和回车符），Text 类型。



案例：

文本如下

```
Rich learning form
Intelligent learning engine
Learning more convenient
From the real demand for more close to the enterprise
```



读取后的KV如下

```
(0,Rich learning form)
(20,Intelligent learning engine)
(49,Learning more convenient)
(74,From the real demand for more close to the enterprise)
```



## CombineTextInputFormat

### 切片机制

框架默认的 TextInputFormat 切片机制是对任务按文件规划切片，不管文件多小，都会 是一个单独的切片，都会交给一个 MapTask，这样如果有大量小文件，就会产生大量的 MapTask，处理效率极其低下。



而 CombineTextInputFormat 用于**小文件过多的场景**，它可以将**多个小文件从逻辑上规划到一个切片中**，这样，多个小文件就可以交给一个 MapTask 处理。



**切片机制**

虚拟存储过程和切片过程二部分。

![image-20220717134523096](.\picture\image-20220717134523096.png)

**1、虚拟存储过程**

将输入目录下所有文件大小，依次和设置的 setMaxInputSplitSize 值比较，

如果不大于设置的最大值，逻辑上划分一个块。 （1.7M < 4M 划分一块）

如果输入文件大于设置的最大值且大于两倍， 那么以最大值切割一块； (8.1M ＞ 2*4M 划分 4.0M 和 4.1M)

当剩余数据大小超过设置的最大值且不大于最大值 2 倍，此时将文件均分成 2 个虚拟存储块（防止出现太小切片）（ 4.1M划分成2.05 和 2.05）。 



例如 setMaxInputSplitSize 值为 4M，输入文件大小为 8.02M，则先逻辑上分成一个 4M。剩余的大小为 4.02M，如果按照 4M 逻辑划分，就会出现 0.02M 的小的虚拟存储 文件，所以将剩余的 4.02M 文件切分成（2.01M 和 2.01M）两个文件。

**2、切片过程**

（a）判断虚拟存储的文件大小是否大于 setMaxInputSplitSize 值，大于等于则单独 形成一个切片。 

（b）如果不大于则跟下一个虚拟存储文件进行合并，共同形成一个切片。 



测试举例：有 4 个小文件大小分别为 1.7M、5.1M、3.4M 以及 6.8M 这四个小 文件

则虚拟存储之后形成 6 个文件块

大小分别为： 

1.7M，（2.55M、2.55M）、3.4M 、（3.4M、3.4M） 

最终会形成 3 个切片大小分别为： 

（1.7+2.55）M，（2.55+3.4）M，（3.4+3.4）M



### 案例实操

![image-20220717144008255](.\picture\image-20220717144008255.png)

之前的wordCount案例，将输入换成4个文件运行，可以看到

number of splits:4

因为文件都小于128M，所以一个文件一个切片



**修改1**

我们将driver添加如下

```java
//！！！默认使用的是TextInputFormat、需要更改
job.setInputFormatClass(CombineTextInputFormat.class);

//！！！虚拟存储切片最大值设置 4m
CombineTextInputFormat.setMaxInputSplitSize(job, 4194304);
```



setMaxInputSplitSize = 4M

会产生 1.7M+2.6M+2.6M+3.4M+3.4M+3.4M 再两两合并变成4个切片

查看日志：number of splits:3



**修改2**

我们将driver修改如下

```java
//！！！默认使用的是TextInputFormat、需要更改
job.setInputFormatClass(CombineTextInputFormat.class);

//！！！虚拟存储切片最大值设置 20m
CombineTextInputFormat.setMaxInputSplitSize(job, 20971520);
```



setMaxInputSplitSize = 20M

会产生 1.7M+5.2M+3.4M+6.9M 合并变成1个切片

查看日志：number of splits:1



