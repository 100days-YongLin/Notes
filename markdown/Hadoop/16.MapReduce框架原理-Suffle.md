# MR详细工作流程

![image-20220717152034640](.\picture\image-20220717152034640.png)

1、读取待处理文本

2、在客户端submit提交前，获取待处理数据的信息，根据配置信息，形成一个任务分配的规划，切片

3、提交信息给客户端（包括Jobsplit文件、jar包、 JobXML文件）

4、客户端启动YarnRM，YarnRM启动Mrappmaster和NodeManager，计算出MapTask数量，并拉起进程。

5、每个MapTask 在InputFormat读取数据

​	5.1、（默认使用TextInputFormat的RecorderReader），读取一行KV，返回给MapTask

6、MapTask执行Mapper函数，调用map(KV) 和Context.write(k, v)

7、outputCollector 向环形缓冲区写入kv数据

​	7.1、缓冲区分为索引和记录部分

​	索引Meta：index序号、partition分区大小、keystart该分区Key开始序号、valuestart该分区Value开始序号

​	记录Records：key、value、unsued

​	7.2、缓冲区工作原理，从两头开始分别记录，如果有一边记录到80%（距离中线还剩下20%）了，开启另一个线程从中线开始反向写

​	如果反向写的速度追上了原本读的速度，不会覆盖，会直接等待读取完再覆盖

8、缓冲区对分区内数据进行快速排序。（实际上是排索引的顺序，用指针的方式，不改变实际存储的位置）

9、溢写到文件（分区且区内有序）

10、溢写的文件进行归并排序，能保证分区内的是有序的，计算完写到文件里

11、合并同Key项

![image-20220717152627151](.\picture\image-20220717152627151.png)

12、所有MapTask任务完成后，启动相应数量的ReduceTask，并告知ReduceTask处理数据范围

13、ReduceTask主动从不同的MapTask的同一分区拉取数据（拉取自己相应负责的分区），拉取完后进行归并排序，排序完后将相同key值的传送到Reducer函数

14、一次读取一组

16、TextOutputFormat往RecordWriter进行写数据



# Shuffle 机制

**是什么**？

Map之后Reduce之前的 混洗 （数据处理）（洗牌）的过程

![image-20220717165907970](.\picture\image-20220717165907970.png)



# Partition 分区

**做什么**（控制Reduce之前分区的数量，一个reducer控制一个分区，输出一个文件）

要求将统计结果按照条件输出到不同文件中（分区）。比如：将统计结果按照手机 归属地不同省份输出到不同文件中（分区）



## **默认分区代码**

```java
public class HashPartitioner<K, V> extends Partitioner<K, V> {
	public int getPartition(K key, V value, int numReduceTasks) {
		return (key.hashCode() & Integer.MAX_VALUE) % numReduceTasks;
	}
}
```

key.hashCode() & Integer.MAX_VALUE ： 防止HashCode太大，溢出，扔掉溢出的部分

% numReduceTasks ： 要分几个区



**默认分区是根据key的hashCode对ReduceTasks个数取模得到的。用户没法控制哪个 key存储到哪个分区。**



## 自定义（重写）

**方法**

1 自定义类继承Partitioner，重写getPartition()方法

```java
public class CustomPartitioner extends Partitioner<Text, FlowBean> {
	@Override
	public int getPartition(Text key, FlowBean value, int numPartitions) {
        // 控制分区代码逻辑
        … …
        return partition;
    }
}

```



2 在Job驱动中，设置自定义Partitioner

job.setPartitionerClass(CustomPartitioner.class);



3 自定义Partition后，要根据自定义Partitioner的逻辑设置相应数量的ReduceTask

job.setNumReduceTasks(5);

// 如果不写 默认是1 只分一个区



## **自定义案例**

将手机号码分区：

136 - 0区

137 - 1区

138 - 2区

139 - 3区

其他 - 4区



重写partitioner

```java
package com.atguigu.mapreduce.partitioner2;

import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Partitioner;

public class ProvincePartitioner extends Partitioner<Text, FlowBean> {
    @Override
    public int getPartition(Text text, FlowBean flowBean, int numPartitions) {
        //转文本
        String phone = text.toString();

        //取前三位
        String prePhone = phone.substring(0, 3);

        //判断
        int partition;
        if(prePhone.equals("136")){
            partition = 0;
        }else if(prePhone.equals("137")){
            partition = 1;
        }else if(prePhone.equals("138")){
            partition = 2;
        }else if(prePhone.equals("139")){
            partition = 3;
        }else{
            partition = 4;
        }
        return partition;
    }
}
```



driver添加：

```java
job.setPartitionerClass(ProvincePartitioner.class);
job.setNumReduceTasks(5);
```



**ReduceTask数量和分区数量的关系**

如果真正partitioner返回值有0-4

ReduceTask 写1 会使用默认的Partitioner只分一个区，返回一个文件

ReduceTask 写 2、3、4 会报IO异常，因为有的分区找不到对应的ReduceTask

ReduceTask 写≥ 5则没问题，多出来的会以空文件呈现（多的ReduceTask资源空转）



**注意**

分区号必须从0开始，逐一累加



# WritableComparable 排序

## 为啥MR里都要排序？

为了提高效率



## 排序的含金量

排序是MapReduce框架中最重要的操作之一。 MapTask和ReduceTask均会对数据按 照key进行排序。该操作属于 Hadoop的默认行为。任何应用程序中的数据均会被排序，而不管逻辑上是 否需要。



## 什么时候排序

**MapTask**

对于MapTask来说，处理完的数据会放到环形缓冲区，环形缓冲区的数据量到达一定阈值之后，会进行一次**快速排序**，并溢写到磁盘上。当数据处理完毕后，会对磁盘所有的文件 根据分区 进行**归并排序**



**ReduceTask**

从每个MapTask上远程拷贝相应的数据文件，如果文件大小超过一定阈值，会溢写到磁盘上，否则存储再内存中。

如果磁盘上文件数目达到一定阈值，则进行一次归并排序生成一个更大的文件。

如果内存中的文件大小或者数目超过一定阈值，则进行一次合并后将数据溢写到磁盘上。

当所有数据拷贝完毕后，ReduceTask统一对内存和磁盘上的所有数据进行一次**归并排序**



## 排序分类

**部分排序**

MapReduce根据输入记录的键对数据集排序。保证输出的每个文件内部有序。



**全排序**

最终输出结果只有一个文件，且文件内部有序。实现方式是只设置一个ReduceTask。但该方法在 处理大型文件时效率极低，因为一台机器处理所有文件，完全丧失了MapReduce所提供的并行架构。



**辅助排序**（GroupingComparator分组）用的比较少

在Reduce端对key进行分组。应用于：在接收的key为bean对象时，想让一个或几个字段相同（全部 字段比较不相同）的key进入到同一个reduce方法时，可以采用分组排序。



**二次排序**

在自定义排序过程中，如果compareTo中的判断条件为两个即为二次排序。



## 自定义排序原理分析

如果要bean 对象做为 key 传输，需要实现 WritableComparable 接口重写 compareTo 方法，就可以实现排序。

```java
@Override
public int compareTo(FlowBean bean) {
    int result;
    // 按照总流量大小，倒序排列
    if (this.sumFlow > bean.getSumFlow()) {
    	result = -1;
    }else if (this.sumFlow < bean.getSumFlow()) {
    	result = 1;
    }else {
    	result = 0;
    }
    return result;
}

```





## 自定义排序案例

需求：将之前做的电话号码案例，的结果进行总流量倒序排序

输入：

<img src=".\picture\image-20220718004304740.png" alt="image-20220718004304740" style="zoom:50%;" />



1、在自定义Bean里继承writableComparable方法,并实现comparableTo方法（其他部分略）

```java
public class FlowBean implements WritableComparable<FlowBean> {
	@Override
    public int compareTo(FlowBean o) {
        if(this.sumFlow > o.sumFlow){
            return -1;
        }else if(this.sumFlow < o.sumFlow){
            return 1;
        }else
            return 0;
    }
}
```



2、Mapper

```java
package com.atguigu.mapreduce.writableComparable;

import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Mapper;

import java.io.IOException;

public class FlowMapper extends Mapper<LongWritable, Text, FlowBean, Text> {
    private FlowBean outK = new FlowBean();
    private Text outV = new Text();
    @Override
    protected void map(LongWritable key, Text value, Mapper<LongWritable, Text, FlowBean, Text>.Context context) throws IOException, InterruptedException {
        // 读出一行
        String line = value.toString();
        // 切割
        String[] split = line.split("\t");

        // key对象赋值
        outK.setUpFlow(Integer.parseInt(split[1]));
        outK.setDownFlow(Integer.parseInt(split[2]));
        outK.setSumFlow();

        // value对象赋值
        outV.set(split[0]);

        context.write(outK, outV);
    }
}
```



3、reducer

```java
package com.atguigu.mapreduce.writableComparable;

import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Reducer;

import java.io.IOException;

public class FlowReduce extends Reducer<FlowBean, Text, Text, FlowBean> {
    @Override
    protected void reduce(FlowBean key, Iterable<Text> values, Reducer<FlowBean, Text, Text, FlowBean>.Context context) throws IOException, InterruptedException {
        for (Text value : values) {
            context.write(value, key);
        }

    }
}
```



结果：

<img src=".\picture\image-20220718010321583.png" alt="image-20220718010321583" style="zoom:50%;" />



### 二次排序

**添加需求：如果在总流量相同的情况下，对上行流量进行排序，如何进行？**

comparableTo方法，在相等的分支里，继续判断上行流量

```java
public class FlowBean implements WritableComparable<FlowBean> {
	@Override
    public int compareTo(FlowBean o) {
        if(this.sumFlow > o.sumFlow){
            return -1;
        }else if(this.sumFlow < o.sumFlow){
            return 1;
        }else
            if(this.upFlow > o.upFlow){
                return -1;
            }else if(this.upFlow < o.upFlow){
                return 1;
            }else{
                return 0;
            }
    }
}
```



## 区内排序

**添加需求：将137/13/138的输出单个文件，并且要保证内部是排序的**

加一个partition部分就行。





# Combiner 合并

## 是什么

（1）Combiner是MR程序中Mapper和Reducer之外的一种组件。 

（2）Combiner组件的父类就是Reducer。

（3）Combiner和Reducer的区别在于运行的位置 Combiner是在**每一个MapTask所在的节点运行**; 

（4）Combiner的意义就是对每一个MapTask的输出进行**局部汇总**，以减小网络传输量。 

（5）Combiner能够应用的前提是不能影响最终的业务逻辑，而且，**Combiner的输出kv 应该跟Reducer的输入kv类型要对应起来**。



## 自定义 Combiner 实现步骤

自定义一个 Combiner 继承 Reducer，重写 Reduce 方法

```java
public class WordCountCombiner extends Reducer<Text, IntWritable, Text, IntWritable> {
    private IntWritable outV = new IntWritable();
    @Override
    protected void reduce(Text key, Iterable<IntWritable> values, Context context) throws IOException, InterruptedException {
        int sum = 0;
        for (IntWritable value : values) {
        	sum += value.get();
    	}

    outV.set(sum);

    context.write(key,outV);
    }
}
```



在 Job 驱动类中设置

```Java
job.setCombinerClass(WordCountCombiner.class);
```



## 案例

统计过程中对每一个 MapTask 的输出进行局部汇总，以减小网络传输量即采用 Combiner 功能。

![image-20220719164234919](.\picture\image-20220719164234919.png)

Combiner类

```java
package com.atguigu.mapreduce.combinerWc;

import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Reducer;

import java.io.IOException;

public class WordCountCombiner extends Reducer<Text, IntWritable, Text, IntWritable> {
    IntWritable outV = new IntWritable();
    @Override
    protected void reduce(Text key, Iterable<IntWritable> values, Reducer<Text, IntWritable, Text, IntWritable>.Context context) throws IOException, InterruptedException {
        int sum = 0;
        for (IntWritable value : values) {
            sum += value.get();
        }
        outV.set(sum);
        context.write(key, outV);
    }
}
```



driver添加：

```java
job.setCombinerClass(WordCountCombiner.class);
```



查看运行日志：

```
Map-Reduce Framework
		Map input records=6
		Map output records=12
		Map output bytes=126
		Map output materialized bytes=66
		Input split bytes=178
		Combine input records=12
		Combine output records=5
		Reduce input groups=5
		Reduce shuffle bytes=66
		Reduce input records=5
		Reduce output records=5
		Spilled Records=10
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=532676608
```

