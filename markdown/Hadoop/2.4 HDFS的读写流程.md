# HDFS写流程

<img src=".\picture\Snipaste_2022-07-07_14-52-38.png" style="zoom:50%;" />

1.HDFSClient用户访问客户端

2.客户端创建DistributionFileSystem分布式系统

3.分布式系统向NameNode请求上传文件

4.NameNode检查：权限、目录结构（是否已经存在）

5.NameNode检查完 响应给客户端 可以上传文件

6.客户端请求上传第一个Block(0-128M)，请返回DataNode

7.NameNode返回dn1\dn2\dn3节点，表示采用这三个节点存储数据

> 副本存储节点选择：
>
> 7.1 本地节点
>
> 7.2 其他机架一个节点
>
> 7.3 其他机架的另一个节点

8.客户端请求Block传输到dn1通道，传输完毕就不管了。dn1收到后传给dn2，dn2给dn3.

9.dn3接收完毕返回给dn2，dn2应答成功返回给dn1，dn1应答给客户端

> 一个block划分成多个packet，放到缓冲队列里，发送。每一个packet发送 都要收到应答后才成功

10.传输完成





# 网络拓扑-节点距离计算

在HDFS写数据的过程中，NameNode会选择距离待上传数据最近的DataNode接收数据。那么这个最近距离怎么计算呢？

节点距离：两个节点到达最近的共同祖先的距离和

![](.\picture\Snipaste_2022-07-07_14-53-54.png)

Distance(d1/r1/n0, d1/r1/ n0) = 0 同一节点上的进程

Distance(d1/r1/n0, d1, r1, n2) = 2 同一机架上不同节点

Distance(d1/r2/n0, d1, r3, n2) = 4 同一数据中心不同机架上的节点

Distance(d1/r2/n1, d2, r4, n1) = 6 不同数据中心的节点



# 机架感知-副本存储节点选择

![image-20220707145605372](.\picture\image-20220707145605372.png)

```java
// 源码：
protected Node chooseTargetInOrder(int numOfReplicas, 
                               Node writer,
                               final Set<Node> excludedNodes,
                               final long blocksize,
                               final int maxNodesPerRack,
                               final List<DatanodeStorageInfo> results,
                               final boolean avoidStaleNodes,
                               final boolean newBlock,
                               EnumMap<StorageType, Integer> storageTypes)
                               throws NotEnoughReplicasException {
  final int numOfResults = results.size();
  // 第一个副本
  if (numOfResults == 0) {
      //选择本地节点
    DatanodeStorageInfo storageInfo = chooseLocalStorage(writer,
        excludedNodes, blocksize, maxNodesPerRack, results, avoidStaleNodes,
        storageTypes, true);

    writer = (storageInfo != null) ? storageInfo.getDatanodeDescriptor()
                                   : null;

    if (--numOfReplicas == 0) {
      return writer;
    }
  }
  final DatanodeDescriptor dn0 = results.get(0).getDatanodeDescriptor();
    // 第二个副本
  if (numOfResults <= 1) {
      //选择远程节点
    chooseRemoteRack(1, dn0, excludedNodes, blocksize, maxNodesPerRack,
        results, avoidStaleNodes, storageTypes);
    if (--numOfReplicas == 0) {
      return writer;
    }
  }
    // 第三个副本
  if (numOfResults <= 2) {
    final DatanodeDescriptor dn1 = results.get(1).getDatanodeDescriptor();
    if (clusterMap.isOnSameRack(dn0, dn1)) { //如果0和1在同一个机架
      chooseRemoteRack(1, dn0, excludedNodes, blocksize, maxNodesPerRack,
          results, avoidStaleNodes, storageTypes);// 选择远程的
    } else if (newBlock){ //否则选择本地的
      chooseLocalRack(dn1, excludedNodes, blocksize, maxNodesPerRack,
          results, avoidStaleNodes, storageTypes);
    } else {
      chooseLocalRack(writer, excludedNodes, blocksize, maxNodesPerRack,
          results, avoidStaleNodes, storageTypes);
    }
    if (--numOfReplicas == 0) {
      return writer;
    }
  }
  chooseRandom(numOfReplicas, NodeBase.ROOT, excludedNodes, blocksize,
      maxNodesPerRack, results, avoidStaleNodes, storageTypes);
  return writer;
}
```



# HDFS读数据

1.HDFSClient用户访问客户端

2.客户端创建DistributionFileSystem分布式系统

3.请求NameNode下载文件并给出路径

4.NameNode检查路径和权限

5.NameNode返回目标文件的元数据

6.客户端创建FSDataInputStream读数据

7.FSDataInputStream向DataNode请求读数据

8.DataNode传数据回去

选择读取的DataNode会考虑负载情况，下载到满载了就会选择一个轻负载的进行下载（串行读，读完后拼接）

![image-20220707151205717](.\picture\image-20220707151205717.png)